import GlobalStyled from "styles/GlobalStyled";
import React, { useEffect, useState, useRef } from "react";
import TopNavigationBar from "components/common/TopNavigationBar";
import themes from "styles/themes";
import styled from "styled-components";
import iconMike from "../../assets/svgs/iconMike.svg";
import iconNoMike from "../../assets/svgs/iconNoMike.svg";
import Webcam from "react-webcam";
import { Button } from "@mui/material";
import LeftBubble from "components/interview/LeftBubble";
import RightBubble from "components/interview/RightBubble";
import { History, HISTORY_TYPE } from "types/interview/interview-type";
import { useSpeechSynthesis, useSpeechRecognition } from 'react-speech-kit';
import { ReactMediaRecorder, useReactMediaRecorder } from "react-media-recorder";
import { useNavigate, useLocation } from 'react-router-dom';
import { showEmotionPrediction } from "apis/interviewService";
import SocketVideo from "components/socket-video"
import { getEmotionAnalysisResult } from "apis/interviewService";
import { InterviewTitle } from "types/interview/interview-type";

const InterviewRoom: React.FC = () => {
  let navigate = useNavigate();
  const location = useLocation();
  const state = location.state as InterviewTitle;
  const [title, setTitle] = useState<string>(state.title);
  const questions: Array<string> = [
    "ëŒ€í•™êµ ë•Œ ê²ªì€ ê°€ì¥ í¥ë¯¸ë¡œìš´ í™œë™ì´ ë¬´ì—‡ì¸ê°€ìš”?",
    "ê°€ì¥ ì¸ìƒê¹Šì€ ê³¼ëª©ì´ ìˆë‹¤ë©´ í•œê°€ì§€ë¥¼ ë§í•´ì£¼ì„¸ìš”.",
    "ìµœê·¼ ê°€ì¥ ëª°ì…í•œ ê²½í—˜ì´ ë¬´ì—‡ì¸ê°€ìš”?",
    "ëª©í‘œë¥¼ ë‹¬ì„±í•˜ëŠ” ë°©ë²•ì„ ë§í•´ì£¼ì„¸ìš”.",
    "í˜‘ì—…ì„ í•˜ë©° ê°ˆë“± ê²½í—˜ê³¼ í•´ê²°í•œ ë°©ë²•ì„ ë§í•´ì£¼ì„¸ìš”.",
  ];

  const [stage, setStage] = useState<number>(-1); // í˜„ì¬ ì§ˆë¬¸ ë‹¨ê³„
  const [logs, setLogs] = useState<History[]>([
    { text: questions[0], type: HISTORY_TYPE.QUESTION },
  ]); // ì§ˆë¬¸ + ë‹µë³€ ê¸°ë¡ ë°°ì—´
  const [value, setValue] = useState<string>("");
  const [isRecording, setIsRecording] = useState<boolean>(true);
  const [showingEmotion, setShowingEmotion] = useState<boolean>(false);
  const recordedChunks: string[] = [];
  //   const [recordedChunks, setRecordedChunks] = useState<string[]>([]);

  // react webcam
  const webcamRef = useRef<Webcam>(null);
  const mediaRecorderRef = useRef<MediaRecorder>(null);
  const [capturing, setCapturing] = useState<boolean>(false);
  //   const [recordedChunks, setRecordedChunks] = useState<string[]>([]);
  // socket ê´€ë¦¬
  const socketVideoRef = useRef<any>();

  // media recorder
  const { status, startRecording, stopRecording, mediaBlobUrl } =
    useReactMediaRecorder({ audio: true, video: true });

  const startInterviewRecording = () => {
    startRecording();
  };

  const stopInterviewRecording = () => {
    stopRecording();
    setIsRecording(false);
  };

  const { speak } = useSpeechSynthesis();
  const { listen, listening, stop } = useSpeechRecognition({
    onResult: (result: string) => {
      setValue(result);
    },
  });


  const changeShowingEmotion = (e: React.MouseEvent<HTMLButtonElement>) => {
    // api ìš”ì²­ ë³´ë‚´ì•¼í•¨
    setShowingEmotion(!showingEmotion);
  };

  const moveToNext = (e: React.MouseEvent<HTMLButtonElement>) => {
    if (stage == questions.length - 1) {
      listen();
      // ë§ˆì§€ë§‰ ë‹µë³€ ì €ì¥
      const curAnswer: History = { text: value, type: HISTORY_TYPE.ANSWER };
      setLogs([...logs, curAnswer]);

      // ë…¹í™” ì¤‘ì§€
      // stopInterviewRecording();
      // handleStopCapture();
      stop();
    } else {
      // ë‹¤ìŒ ì§ˆë¬¸ ì¶œë ¥
      setStage(stage + 1);

      const curAnswer: History = { text: value, type: HISTORY_TYPE.ANSWER };
      const nextQuestion: History = {
        text: questions[stage + 1],
        type: HISTORY_TYPE.QUESTION,
      };

      setLogs([...logs, curAnswer, nextQuestion]);
      stop();
    }
  };

  // const finishInterview = (e: React.MouseEvent<HTMLButtonElement>) => {
  //   // ë©´ì ‘ ê²°ê³¼ ë°›ì•„ì˜¨ë‹¤
  //   // getEmotionAnalysisResult().then((res) => {
  //   //   const blobUrl = URL.createObjectURL(res.data);
  //   //   const happyPer = res.headers["happy_per"];
  //   //   navigate("/home/interviewResult", {
  //   //     state: {
  //   //       src: blobUrl,
  //   //         happy: happyPer,
  //   //       recordeds: recordedChunks
  //   //     },
  //   //   });
  //   // });
  //   // navigate("/home/interviewList");
  //   navigate("/home/interviewResult", {state : {recordeds: recordedChunks}});
  // };

  // ìµœì´ˆ ë Œë”ë§ ì‹œ ë…¹í™” ì‹œì‘
  useEffect(() => {
    // startInterviewRecording();
    // handleStartCapture();
  }, []);

  useEffect(() => {
    showEmotionPrediction(showingEmotion ? "true" : "false");
  }, [showingEmotion]);

  // stageê°€ ë³€í•  ë•Œ ë§ˆë‹¤ ì§ˆë¬¸ ì½ì–´ì¤€ë‹¤.
  useEffect(() => {
    if (stage < 0) setStage(0);
    speak({ text: questions[stage] });
  }, [stage]);

  const handleSpeaking = (e: React.MouseEvent<HTMLDivElement>) => {
    if (!listening)
      listen();
  }

  // SocketVideo ì»´í¬ë„ŒíŠ¸ì—ì„œ í•¨ìˆ˜ë¥¼ ë°›ì•„ì˜¤ê¸° ìœ„í•¨
  let finishInterview = () => { }
  const finishConnector = (endSocket: () => void) => {
    finishInterview = endSocket;
  }

  // ì‹¤ì œ ë©´ì ‘ ì¢…ë£Œì‹œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜
  const onFinish = () => {
    finishInterview();
    // navigate("/home/interviewList");
    navigate("/home/interviewResult", { state: { recordeds: recordedChunks } });
  }

  return (
    <GlobalStyled.ViewCol style={{ backgroundColor: themes.colors.background }}>
      <TopNavigationBar state="ëª¨ì˜ ë©´ì ‘" />
      <GlobalStyled.ViewRow style={{ display: 'block' }}>
        <GlobalStyled.ViewCol className="webcam-div" style={{ flex: 4, float: 'left', width: '48%' }}>
          <BlueBox style={{ flex: 1, paddingTop: 20, paddingBottom: 20, justifyContent: 'center' }}>
            <div className="interview-title">{title}</div>
          </BlueBox>
          {/* <object type="text/html" data="http://localhost:8000/" style={{width:'100%', height:'100%'}}></object> */}
          <SocketVideo finishConnector={finishConnector} webSocketUrl={'ws://localhost:8000/emotion-cam'} showing={showingEmotion} recordedChunks={recordedChunks}></SocketVideo>

          <BlueBox
            className="media-box"
            style={{ display: 'block', flex: 1, paddingLeft: 30, paddingRight: 30, height: 80 }}>

            <Button
              className="emotion-show-btn"
              disableElevation
              variant="contained"
              onClick={changeShowingEmotion}
              style={{
                // backgroundColor: 'white',
                // color: themes.colors.main_blue,
                backgroundColor: "transparent",
                padding: 0,
                fontSize: "1.8rem",
              }}
            >
              {showingEmotion ? "ğŸ™„" : "ğŸ˜ƒ"}
            </Button>

            <Button
              className="next-btn"
              disableElevation
              variant="contained"
              onClick={stage < questions.length - 1 ? moveToNext : onFinish}
              style={{
                float: 'right',
                backgroundColor: 'white',
                color: themes.colors.main_blue,
                fontWeight: 800,
                marginTop: 5 
              }}
            >
              {stage == questions.length - 1 ? "ë©´ì ‘ ì¢…ë£Œ" : "ë‹¤ìŒìœ¼ë¡œ"}
            </Button>

            <div onClick={handleSpeaking} style={{ cursor: "pointer", float: 'right', marginRight: 20, marginTop: 5 }}>
              <img src={listening ? iconMike : iconNoMike} />
            </div>

            {listening && <div style={{ float: 'right', alignSelf: 'center', marginTop: 10, marginRight: 10 }}>ë‹µë³€ì¤‘...</div>}
          </BlueBox>
        </GlobalStyled.ViewCol>

        <GlobalStyled.ViewCol className="history-div" style={{ flex: 4, height: '90vh' }}>
          <BlueBox style={{ flex: 1, paddingTop: 20, paddingBottom: 20, justifyContent: 'center' }}>
            <div>ëŒ€í™” ê¸°ë¡</div>
          </BlueBox>

          <GlobalStyled.ViewCol style={{ flex: 30, backgroundColor: 'white', overflow: 'auto' }}>
            {
              logs.map((log, idx) => {
                return (
                  log.type == HISTORY_TYPE.QUESTION ?
                    <LeftBubble text={log.text} /> :
                    <RightBubble text={log.text} />
                )
              })
            }
          </GlobalStyled.ViewCol>
        </GlobalStyled.ViewCol>
      </GlobalStyled.ViewRow>
    </GlobalStyled.ViewCol >
  );
}

const BlueBox = styled(GlobalStyled.ViewRow)`
    background-color: ${themes.colors.main_blue};
    color: ${themes.colors.white};
    font-weight: 600;
    padding-top: 10px;
    padding-bottom: 10px;
    width: 'auto';
    height: '10%';
`;


export default InterviewRoom;